#+TITLE: 通用矩阵乘法实验报告
#+OPTIONS: toc:nil num:3 H:4 ^:nil pri:t
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://gongzhitaao.org/orgcss/org.css"/>

** 引言

*** 为什么需要矩阵乘
矩阵是线性代数的基础概念，也是现代计算机所要经常处理的数据结构之一，在诸如计算机图形学、人工智能、信息学、基础学科研究中发挥着重要作用（尤其是，在我所学的范畴内，数学建模和信号处理中尤其常用矩阵）。

在我们学校开设的“线性代数”（或高等代数）课中，我们已经在数学上认识了矩阵及其运算和性质等，但是抽象的数学描述距离真正实用地运用它为我们做实事还有一段相当的距离。所以考虑如何使用计算机储存、操作矩阵是非常具有实际意义的一件事情。

*** 矩阵在计算机的表示
我们知道，矩阵本质上仅仅是一系列数按照特定的结构（或者说顺序）排列，这很容易让我们联想到我们在 c 语言程序设计课程中学习过的数组的概念，尤其是储存数字类型的数组。这是否会为我们提供一个思路呢？让我们沿着这个想法继续思考下去，第一个问题是显而易见的——矩阵是既有行又有列的，而一般我们所讲的数组都是一维数组！

有两个巧妙的办法可以解决这个问题。比较容易理解的一个是，既然一个数组表示一组有顺序的数，而矩阵可以看作是由许多排顺序存放的数——即多个数组所组成的，是有序存放的数组，那么我们创建一个二维数组，即数组的数组是不是就可以顺利的表示一个完整的矩阵列呢？答案是肯定的，二维数组与矩阵惊人的相似之处让这一点几乎不言自明。

从朴素的角度来看，数组的“本体”是一块拥有足够多到容纳下自身内容的 *内存空间* （具体储存的位置在栈或者堆上），而我们在代码中所声明和操作的数组名则是指向这块内存首地址的 *一个指针* ，这个指针储存在栈上（如果使用 malloc 分配内存的话，其指向的内存位于堆上）。通过这个指针，外加 c 语言中支持的对指针的算术操作，就可以访问到数组中任何一个元素。

那么二维数组的一个实现思路便是，创建这样一个数组——它的内容由许多 *指向其他数组的指针* 组成，即——指向指针的指针，我们称之为二级指针。当我们想要操作矩阵中 m 行 n 列的数据时，只需要把对应二级指针的第 m 个元素取出，然后取出这个元素指向的数组的第 n 元素即可。整个过程只需要两次寻址，看起来十分便利。但是这会造成矩阵在内存中的位置碎片化等问题，也不利于内存管理。

第二种方式则是，将二维的矩阵全部储存在一维的数组里，具体的操作是，将后一行排在前一行的末尾，这样子首尾衔接，就可以在一条连续的空间中完整地储存矩阵。这其实也是 c 语言中对二维数组的处理方式。

本报告采取第二种方式。考虑到矩阵规模较大，故全部使用 malloc 函数动态分配内存。

** 实验要求

用 c 语言实现矩阵乘

输入： M 、 N 、 K 三个整数（512～2048）

问题描述：随机生成 M*N 和N*K 的两个矩阵 A,B,对这两个矩阵，做乘法得到矩阵 C。

输出：A,B,C 三个矩阵以及矩阵计算的时间。

** 实验过程

*** 朴素的定义法

依据矩阵乘法定义所实现的朴素矩阵乘法代码如下：

#+begin_src
void matrix_mul(matrix_t matrix_r,              \
                matrix_t matrix1,               \
                matrix_t matrix2,               \
                dim_t m, dim_t n, dim_t k) {
    for (dim_t i1 = 0; i1 < m; i1++) {
        for (dim_t i2 = 0; i2 < k; i2++) {
            /* malloc initliaze memory to 0 by default
             *
             * C[i1][i2] = 0
             */
            for (dim_t i3 = 0; i3 < n; i3++) {
                // C[i1][i2] += A[i1][i3] * B[i3][i2]
                matrix_r[i1 * k + i2] +=    \
                    matrix1[i1 * n + i3] *  \
                    matrix2[i3 * k + i2];
            }
        }
    }
}
#+end_src

这里只展示其算法实现部分。结果为运行十次取其平均值，如下表所示：

|    M |    N |    K | 平均时间（s） |
|------+------+------+---------------|
|  512 |  512 |  512 |      0.506073 |
| 1024 | 1024 | 1024 |      4.133914 |
| 2048 | 2048 | 2048 |     37.469813 |

*** 循环拆分

A 与 B 矩阵每个元素都会多次参加运算，但是在朴素算法中我们在最内层循环每次都对一个元素只使用一次，等到第二次使用到这个元素时又需要重新加载其到缓存中，循环拆分可以通过数据重用来解决这个问题。

#+begin_src
void matrix_mul(matrix_t matrix_r,              \
                matrix_t matrix1,               \
                matrix_t matrix2,               \
                dim_t m, dim_t n, dim_t k) {
    for (dim_t i1 = 0; i1 < m; i1++) {
        for (dim_t i2 = 0; i2 < k; i2 += 4) {
            /* malloc initliaze memory to 0 by default
             *
             * C[i1][i2] = 0
             * C[i1][i2 + 1] = 0
             * C[i1][i2 + 2] = 0
             * C[i1][i2 + 3] = 0
             */
            for (dim_t i3 = 0; i3 < n; i3++) {
                // C[i1][i2] += A[i1][i3] * B[i3][i2]
                matrix_r[i1 * k + i2] +=    \
                    matrix1[i1 * n + i3] *  \
                    matrix2[i3 * k + i2];
                // C[i1][i2 + 1] += A[i1][i3] * B[i3][i2 + 1]
                matrix_r[i1 * k + i2 + 1] +=    \
                    matrix1[i1 * n + i3] *      \
                    matrix2[i3 * k + i2 + 1];
                // C[i1][i2 + 2] += A[i1][i3] * B[i3][i2 + 2]
                matrix_r[i1 * k + i2 + 2] +=    \
                    matrix1[i1 * n + i3] *      \
                    matrix2[i3 * k + i2 + 2];
                // C[i1][i2 + 3] += A[i1][i3] * B[i3][i2 + 3]
                matrix_r[i1 * k + i2 + 3] +=    \
                    matrix1[i1 * n + i3] *      \
                    matrix2[i3 * k + i2 + 3];
            }
        }
    }
}
#+end_src

在上面的代码中，最内层循环重复使用了 A[i1][i3] 这个元素，这会减少因反复加载同一数据产生的开销（可以类比为，你的一个室友每隔一会就叫你过去帮她做一件事情，与将你叫过去一次把你要做的所有事情都做完，显然后者效率更高）

运行结果：

|    M |    N |    K |  平均时间 |
|------+------+------+-----------|
|  512 |  512 |  512 |  0.469599 |
| 1024 | 1024 | 1024 |  3.735270 |
| 2048 | 2048 | 2048 | 30.425695 |

与朴素算法的对比：

| 矩阵维数 |  朴素算法 |  一层拆分 | 加速比 |
|----------+-----------+-----------+--------|
|      512 |  0.506073 |  0.469599 | 1.0777 |
|     1024 |  4.133914 |  3.735270 | 1.1067 |
|     2048 | 37.469813 | 30.425695 | 1.2315 |

可以看到，在三种规模的矩阵运算中时间均有缩减，加速比随着矩阵规模增大而呈现上升趋势。

*** 编译器选项优化

编译时使用 -O2 选项，编译器会根据代码自行进行优化，实验结果如下：

|    m |  朴素算法 | 平均时间 | 加速比 |
|------+-----------+----------+--------|
|  512 |  0.506073 | 0.105688 | 4.7884 |
| 1024 |  4.133914 | 0.929409 | 4.4479 |
| 2048 | 37.469813 | 7.503153 | 4.9939 |

可以看到，现代编译器是十分强大的！仅仅是一个编译选项就带给了我们几乎5倍的时间优化。

除此之外，在使用编译选项优化前对代码进行适当的手动优化也是有益处的，大家不妨试一试对朴素算法使用 -O2 选项，将结果与对循环拆分后的结果进行对比。

*** 交换循环次序

在朴素算法中，每次内循环就会变动一次矩阵 B 的列标，而 c 语言中数组是按照行储存的，这意味着内循环每进行一次就要重新载入 B 中需要参与运算的数据，但是只会用到其中一个数据，这会造成缓存命中率低。

#+begin_src
void matrix_mul(matrix_t matrix_r,              \
                matrix_t matrix1,               \
                matrix_t matrix2,               \
                dim_t m, dim_t n, dim_t k) {
    for (dim_t i1 = 0; i1 < m; i1++) {
        for (dim_t i2 = 0; i2 < n; i2++) {
            
            for (dim_t i3 = 0; i3 < k; i3++) {
                /* malloc initliaze memory to 0 by default
                 *
                 * C[i1][i3] += A[i1][i2] * B[i2][i3]
                 *
                 */
                matrix_r[i1 * k + i3] +=    \
                    matrix1[i1 * n + i2] *  \
                    matrix2[i2 * k + i3];
            }
        }
    }
}
#+end_src

加上 -O2 选项后，结果如下：

| 矩阵维数 | 朴素算法（-O2） | 交换循环次序（-O2） | 加速比 |
|----------+-----------------+---------------------+--------|
|      512 |        0.371025 |            0.049969 | 7.4251 |
|     1024 |        3.624517 |            0.380877 | 9.5162 |
|     2048 |       26.144212 |            3.057140 | 8.5519 |

可以明显看到，加速效果极其明显。这是因为在优化后的代码中的最内层循环中，矩阵 C 与 B 每次变动列标，而矩阵 B 在每次第二层循环时变动行表，相比朴素算法，数据重用的次数大大增加（甚至相比进行了循环拆分后还要多）。这大大增加了缓存命中率，并且由于同一个数据被反复多次使用，编译器优化时会使用寄存器储存它，大大减少了因缓存读取造成的开销。

使用 perf 分析朴素算法的结果如下：

#+begin_src
Performance counter stats for './mul':

     1,417,345,420      cache-references:u        #  277.442 M/sec                  
        33,748,097      cache-misses:u            #    2.381 % of all cache refs    
          5,108.63 msec task-clock:u              #    0.610 CPUs utilized          
                 0      context-switches:u        #    0.000 /sec                   
                 0      cpu-migrations:u          #    0.000 /sec                   
             1,082      page-faults:u             #  211.799 /sec                   
    21,891,199,333      cycles:u                  #    4.285 GHz                    

       8.368968740 seconds time elapsed

       5.109299000 seconds user
       0.000000000 seconds sys
#+end_src

使用 perf 分析交换循环次序后的结果如下：

#+begin_src
 Performance counter stats for './mul':

     1,568,893,823      cache-references:u        #  430.631 M/sec                  
        33,074,293      cache-misses:u            #    2.108 % of all cache refs    
          3,643.24 msec task-clock:u              #    0.503 CPUs utilized          
                 0      context-switches:u        #    0.000 /sec                   
                 0      cpu-migrations:u          #    0.000 /sec                   
             1,085      page-faults:u             #  297.812 /sec                   
    15,884,304,284      cycles:u                  #    4.360 GHz                    

       7.245727861 seconds time elapsed

       3.640509000 seconds user
       0.003330000 seconds sys
#+end_src

对比可以看到，缓存命中率 cache-references 一项后者大大高于前者。

这同时也印证了前面所说，在使用编译选项前对代码进行合理优化结果会大不一样。

*** Coppersmith–Winograd 算法

截至到现在，使用的方法都还是基于朴素的算法进行改进，尽管可以得到可观的加速比，但是其算法层面的局限性决定了我们必须使用三个 for 循环，也就是时间复杂度为 O(n^3) ，随着矩阵规模逐渐扩大，其时间会呈现三次函数的趋势迅速增加。

除了朴素算法之外，我们还有其他可供选择的算法，它们的时间复杂度低于朴素算法。这意味着随着矩阵规模越来越大，这种算法在时间上的优势也会越来越大。

#+begin_src
void cw(matrix_t matrix_r, matrix_t matrix1, matrix_t matrix2, dim_t n) {
    if (n == 2) {
        matrix_mul(matrix_r, matrix1, matrix2, 4, 4, 4);
        return;
    }

    matrix_t a11 = malloc(sizeof(element_t) * n * n * 8);
    matrix_t a12 = a11 + n * n;
    matrix_t a21 = a12 + n * n;
    matrix_t a22 = a21 + n * n;
    part_matrix(matrix1, a11, a12, a21, a22, n);
    matrix_t b11 = a22 + n * n;
    matrix_t b12 = b11 + n * n;
    matrix_t b21 = b12 + n * n;
    matrix_t b22 = b21 + n * n;
    part_matrix(matrix2, b11, b12, b21, b22, n);
    
    matrix_t s1 = matrix1;
    matrix_t s2 = s1 + n * n;
    matrix_t s3 = s2 + n * n;
    matrix_t s4 = s3 + n * n;
    matrix_t t1 = matrix2;
    matrix_t t2 = t1 + n * n;
    matrix_t t3 = t2 + n * n;
    matrix_t t4 = t3 + n * n;
    
    matrix_add(s1, a21, a22, n, n);
    matrix_sub(s2, s1, a11, n, n);
    matrix_sub(s3, a11, a21, n, n);
    matrix_sub(s4, a12, s2, n, n);
    matrix_sub(t1, b12, b11, n, n);
    matrix_sub(t2, b22, t1, n, n);
    matrix_sub(t3, b22, b12, n, n);
    matrix_sub(t4, t2, b21, n, n);
    
    matrix_t m1 = a21;
    memset(m1, 0, sizeof(element_t) * n * n);
    cw(m1, a11, b11, n / 2);
    matrix_t m2 = a11;
    memset(m2, 0, sizeof(element_t) * n * n);
    cw(m2, a12, b21, n/2);
    matrix_t m3 = a12;
    memset(m3, 0, sizeof(element_t) * n * n);
    cw(m3, s4, b22, n/2);
    matrix_t m4 = s4;
    memset(m4, 0, sizeof(element_t) * n * n);
    cw(m4, a22, t4, n/2);
    matrix_t m5 = a22;
    memset(m5, 0, sizeof(element_t) * n * n);
    cw(m5, s1, t1, n/2);
    matrix_t m6 = s1;
    memset(m6, 0, sizeof(element_t) * n * n);
    cw(m6, s2, t2, n/2);
    matrix_t m7 = s2;
    memset(m7, 0, sizeof(element_t) * n * n);
    cw(m7, s3, t3, n/2);

    matrix_t u1 = b11;
    matrix_t u2 = b12;
    matrix_t u3 = b21;
    matrix_t u4 = b22;
    matrix_t u5 = s3;
    matrix_t u6 = s4;
    matrix_t u7 = t1;
   
    matrix_add(u1, m1, m2, n, n);
    matrix_add(u2, m1, m6, n, n);
    matrix_add(u3, u2, m7, n, n);
    matrix_add(u4, u2, m5, n, n);
    matrix_add(u5, u4, m3, n, n);
    matrix_sub(u6, u3, m4, n, n);
    matrix_add(u7, u3, m5, n, n);
    
    matrix_t c11 = u1;
    matrix_t c12 = u5;
    matrix_t c21 = u6;
    matrix_t c22 = u7;    
    comb_matrix(matrix_r, c11, c12, c21, c22, n);

    free(a11);
}
#+end_src

在未添加任何编译器优化参数的情况下，运行结果如下：

| 矩阵维数 |  朴素算法 | Coppersmith–Winograd | 加速比 |
|----------+-----------+----------------------+--------|
|      512 |  0.506073 |             0.352850 | 1.4342 |
|     1024 |  4.133914 |             2.553325 | 1.6190 |
|     2048 | 37.469813 |            18.096058 | 2.0706 |

可以看出，加速效果也十分明显，并且理论上讲，如果继续扩大矩阵规模，这个优势会越来越大。

** 实验总结

矩阵相乘作为一种广泛应用于各学科的运算，对其的优化是具有重大意义的。作为学生的我们，在动手中理解并掌握矩阵优化的具体方法，是大有裨益的。

在这次实验中，自己看到了编写代码时粗心大意的短板，磕磕绊绊也总算完成了目标，希望自己今后能够学到更多，进步更多。
