* 通用矩阵乘法实验报告

** 引言

*** 为什么需要矩阵乘
矩阵是线性代数的基础概念，也是现代计算机所要经常处理的数据结构之一，在诸如计算机图形学、人工智能、信息学、基础学科研究中发挥着重要作用（尤其是，在我所学的范畴内，数学建模和信号处理中尤其常用矩阵）。

在我们学校开设的“线性代数”（或高等代数）课中，我们已经在数学上认识了矩阵及其运算和性质等，但是抽象的数学描述距离真正实用地运用它为我们做实事还有一段相当的距离。所以考虑如何使用计算机储存、操作矩阵是非常具有实际意义的一件事情。

*** 矩阵在计算机的表示
我们知道，矩阵本质上仅仅是一系列数按照特定的结构（或者说顺序）排列，这很容易让我们联想到我们在 c 语言程序设计课程中学习过的数组的概念，尤其是储存数字类型的数组。这是否会为我们提供一个思路呢？让我们沿着这个想法继续思考下去，第一个问题是显而易见的——矩阵是既有行又有列的，而一般我们所讲的数组都是一维数组！

有两个巧妙的办法可以解决这个问题。比较容易理解的一个是，既然一个数组表示一组有顺序的数，而矩阵可以看作是由许多排顺序存放的数——即多个数组所组成的，是有序存放的数组，那么我们创建一个二维数组，即数组的数组是不是就可以顺利的表示一个完整的矩阵列呢？答案是肯定的，二维数组与矩阵惊人的相似之处让这一点几乎不言自明。

从朴素的角度来看，数组的“本体”是一块拥有足够多到容纳下自身内容的 *内存空间* （具体储存的位置在栈或者堆上），而我们在代码中所声明和操作的数组名则是指向这块内存首地址的 *一个指针* ，这个指针储存在栈上（如果使用 malloc 分配内存的话，其指向的内存位于堆上）。通过这个指针，外加 c 语言中支持的对指针的算术操作，就可以访问到数组中任何一个元素。

那么二维数组的一个实现思路便是，创建这样一个数组——它的内容由许多 *指向其他数组的指针* 组成，即——指向指针的指针，我们称之为二级指针。当我们想要操作矩阵中 m 行 n 列的数据时，只需要把对应二级指针的第 m 个元素取出，然后取出这个元素指向的数组的第 n 元素即可。整个过程只需要两次寻址，看起来十分便利。但是这会造成矩阵在内存中的位置碎片化等问题，也不利于内存管理。

第二种方式则是，将二维的矩阵全部储存在一维的数组里，具体的操作是，将后一行排在前一行的末尾，这样子首尾衔接，就可以在一条连续的空间中完整地储存矩阵。这其实也是 c 语言中对二维数组的处理方式。

本报告采取第二种方式。考虑到矩阵规模较大，故全部使用 malloc 函数动态分配内存。

** 实验要求

用 c 语言实现矩阵乘

输入： M 、 N 、 K 三个整数（512～2048）

问题描述：随机生成 M*N 和N*K 的两个矩阵 A,B,对这两个矩阵，做乘法得到矩阵 C。

输出：A,B,C 三个矩阵以及矩阵计算的时间。

** 实验过程

*** 朴素的定义法

依据矩阵乘法定义所实现的朴素矩阵乘法代码如下：

#+begin_src
void matrix_mul(matrix_t matrix_r,              \
                matrix_t matrix1,               \
                matrix_t matrix2,               \
                dim_t m, dim_t n, dim_t k) {
    for (dim_t i1 = 0; i1 < m; i1++) {
        for (dim_t i2 = 0; i2 < k; i2++) {
            /* malloc initliaze memory to 0 by default
             *
             * C[i1][i2] = 0
             */
            for (dim_t i3 = 0; i3 < n; i3++) {
                // C[i1][i2] += A[i1][i3] * B[i3][i2]
                matrix_r[i1 * k + i2] +=    \
                    matrix1[i1 * n + i3] *  \
                    matrix2[i3 * k + i2];
            }
        }
    }
}
#+end_src

这里只展示其算法实现部分。结果为运行十次取其平均值，如下表所示：

|    M |    N |    K | 平均时间（s） |
|------+------+------+---------------|
|  512 |  512 |  512 |      0.506073 |
| 1024 | 1024 | 1024 |      4.133914 |
| 2048 | 2048 | 2048 |     37.469813 |

*** 循环拆分

#+begin_src
void matrix_mul(matrix_t matrix_r,              \
                matrix_t matrix1,               \
                matrix_t matrix2,               \
                dim_t m, dim_t n, dim_t k) {
    for (dim_t i1 = 0; i1 < m; i1++) {
        for (dim_t i2 = 0; i2 < k; i2 += 4) {
            /* malloc initliaze memory to 0 by default
             *
             * C[i1][i2] = 0
             * C[i1][i2 + 1] = 0
             * C[i1][i2 + 2] = 0
             * C[i1][i2 + 3] = 0
             */
            for (dim_t i3 = 0; i3 < n; i3++) {
                // C[i1][i2] += A[i1][i3] * B[i3][i2]
                matrix_r[i1 * k + i2] +=    \
                    matrix1[i1 * n + i3] *  \
                    matrix2[i3 * k + i2];
                // C[i1][i2 + 1] += A[i1][i3] * B[i3][i2 + 1]
                matrix_r[i1 * k + i2 + 1] +=    \
                    matrix1[i1 * n + i3] *      \
                    matrix2[i3 * k + i2 + 1];
                // C[i1][i2 + 2] += A[i1][i3] * B[i3][i2 + 2]
                matrix_r[i1 * k + i2 + 2] +=    \
                    matrix1[i1 * n + i3] *      \
                    matrix2[i3 * k + i2 + 2];
                // C[i1][i2 + 3] += A[i1][i3] * B[i3][i2 + 3]
                matrix_r[i1 * k + i2 + 3] +=    \
                    matrix1[i1 * n + i3] *      \
                    matrix2[i3 * k + i2 + 3];
            }
        }
    }
}
#+end_src

运行结果：

|    M |    N |    K |  平均时间 |
|------+------+------+-----------|
|  512 |  512 |  512 |  0.469599 |
| 1024 | 1024 | 1024 |  3.735270 |
| 2048 | 2048 | 2048 | 30.425695 |

与朴素算法的对比：

| 矩阵维数 |  朴素算法 |  一层拆分 | 加速比 |
|----------+-----------+-----------+--------|
|      512 |  0.506073 |  0.469599 | 1.0777 |
|     1024 |  4.133914 |  3.735270 | 1.1067 |
|     2048 | 37.469813 | 30.425695 | 1.2315 |

可以看到，在三种规模的矩阵运算中时间均有缩减，加速比随着矩阵规模增大而呈现上升趋势。

*** 编译器选项优化

编译时使用 -O2 选项，编译器会根据代码自行进行优化，实验结果如下：

|    m |  朴素算法 | 平均时间 | 加速比 |
|------+-----------+----------+--------|
|  512 |  0.506073 | 0.105688 | 4.7884 |
| 1024 |  4.133914 | 0.929409 | 4.4479 |
| 2048 | 37.469813 | 7.503153 | 4.9939 |

可以看到，现代编译器是十分强大的！仅仅是一个编译选项就带给了我们几乎5倍的时间优化。

除此之外，在使用编译选项优化前对代码进行适当的手动优化也是有益处的，大家不妨试一试对朴素算法使用 -O2 选项，将结果与对循环拆分后的结果进行对比。

*** 交换循环次序

在朴素算法中，每次内循环就会变动一次矩阵 B 的列标，而 c 语言中数组是按照行储存的，这意味着内循环每进行一次就要重新载入 B 中需要参与运算的数据，但是只会用到其中一个数据，这会造成缓存命中率低。

#+bedin_src
void matrix_mul(matrix_t matrix_r,              \
                matrix_t matrix1,               \
                matrix_t matrix2,               \
                dim_t m, dim_t n, dim_t k) {
    for (dim_t i1 = 0; i1 < m; i1++) {
        for (dim_t i2 = 0; i2 < n; i2++) {
            
            for (dim_t i3 = 0; i3 < k; i3++) {
                /* malloc initliaze memory to 0 by default
                 *
                 * C[i1][i3] += A[i1][i2] * B[i2][i3]
                 *
                 */
                matrix_r[i1 * k + i3] +=    \
                    matrix1[i1 * n + i2] *  \
                    matrix2[i2 * k + i3];
            }
        }
    }
}
#+end_src

加上 -O2 选项后，结果如下：

| 矩阵维数 | 朴素算法（-O2） | 交换循环次序（-O2） | 加速比 |
|----------+-----------------+---------------------+--------|
|      512 |        0.371025 |            0.049969 | 7.4251 |
|     1024 |        3.624517 |            0.380877 | 9.5162 |
|     2048 |       26.144212 |            3.057140 | 8.5519 |

可以明显看到，加速效果极其明显。这是因为在优化后的代码中的最内层循环中，矩阵 C 与 B 每次变动列标，而矩阵 B 在每次第二层循环时变动行表，相比朴素算法，数据重用的次数大大增加（甚至相比进行了循环拆分后还要多）。这大大增加了缓存命中率，并且由于同一个数据被反复多次使用，编译器优化时会使用寄存器储存它，大大减少了因缓存读取造成的开销。

使用 perf 分析朴素算法的结果如下：

#+begin_src
Performance counter stats for './mul':

     1,417,345,420      cache-references:u        #  277.442 M/sec                  
        33,748,097      cache-misses:u            #    2.381 % of all cache refs    
          5,108.63 msec task-clock:u              #    0.610 CPUs utilized          
                 0      context-switches:u        #    0.000 /sec                   
                 0      cpu-migrations:u          #    0.000 /sec                   
             1,082      page-faults:u             #  211.799 /sec                   
    21,891,199,333      cycles:u                  #    4.285 GHz                    

       8.368968740 seconds time elapsed

       5.109299000 seconds user
       0.000000000 seconds sys
#+end_src

使用 perf 分析交换循环次序后的结果如下：

#+begin_src
 Performance counter stats for './mul':

     1,568,893,823      cache-references:u        #  430.631 M/sec                  
        33,074,293      cache-misses:u            #    2.108 % of all cache refs    
          3,643.24 msec task-clock:u              #    0.503 CPUs utilized          
                 0      context-switches:u        #    0.000 /sec                   
                 0      cpu-migrations:u          #    0.000 /sec                   
             1,085      page-faults:u             #  297.812 /sec                   
    15,884,304,284      cycles:u                  #    4.360 GHz                    

       7.245727861 seconds time elapsed

       3.640509000 seconds user
       0.003330000 seconds sys
#+end_src

对比可以看到，缓存命中率 cache-references 一项后者大大高于前者。

这同时也印证了前面所说，在使用编译选项前对代码进行合理优化结果会大不一样。

